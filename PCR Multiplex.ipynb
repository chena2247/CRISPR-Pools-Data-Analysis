{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import generic_dna, generic_protein\n",
    "import sys\n",
    "import os\n",
    "from Bio.SeqIO.QualityIO import FastqGeneralIterator\n",
    "from Bio.Blast import NCBIXML\n",
    "from Bio.Blast.Applications import NcbiblastxCommandline\n",
    "from Bio.Seq import Seq\n",
    "import subprocess\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "SeqFilePath = '/Users/annechen/Downloads/CRISPR Pools Data/test2'\n",
    "PrimerID = '/Users/annechen/Downloads/sgRNAs for multiplexed CRISPR - Primer Sequences Only.csv'\n",
    "\n",
    "output_folder = join(SeqFilePath, 'testout')\n",
    "## Attempting to put data in separate output_folder\n",
    "if not os.path.isdir(output_folder): \n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "def primerfreq(SeqFile, start_index):\n",
    "    \n",
    "    ############################################################################\n",
    "    ## Load CSV File of Primer IDs into pandas dataframe\n",
    "    \n",
    "    primer = pd.read_csv(PrimerID)\n",
    "    primer['Frequency'] = 0\n",
    "    \n",
    "    ############################################################################\n",
    "    ## Make a dictionary for sequences\n",
    "    ## Read in the fastq file  \n",
    "\n",
    "    SeqDict = {}\n",
    "    freq = {}\n",
    "\n",
    "    with open(SeqFile, 'rU') as handle:\n",
    "        for record in SeqIO.parse(handle, \"fastq\"):\n",
    "            SeqDict[str(record.id)] = str(record.seq)\n",
    "            #ProbeseqList.append(str(record.id)) ## Also make a list of all of the probe sequences for writing the output file.\n",
    "\n",
    "    ############################################################################\n",
    "    ##  Make Dictionary by looping through list and count the frequencies\n",
    "\n",
    "    for record in SeqDict:\n",
    "        seq = str(SeqDict[record])\n",
    "        added = False\n",
    "        newcode = ''\n",
    "        if seq[-8:] != 'GGGGGGGG':\n",
    "            for i in freq:\n",
    "                if i[0:15] == seq[0:15]:\n",
    "                    freq[i] = freq[i] + 1\n",
    "                    added = True\n",
    "                else:\n",
    "                    newcode = seq[0:15]\n",
    "            if added == False:\n",
    "                freq[newcode] = 1\n",
    "\n",
    "    ############################################################################\n",
    "    ##  Convert previous dictionary to dataframe \n",
    "\n",
    "    fTable = pd.DataFrame.from_dict(freq, orient='index', columns=['Frequency'])\n",
    "    fTable = fTable.sort_values('Frequency',ascending=False)\n",
    "    fTable['ID'] = '-'\n",
    "    \n",
    "    ############################################################################\n",
    "    ##  Enter matching primer ID if exists on fTable\n",
    "    ##  Enter frequency of appearance on primer dataframe\n",
    "\n",
    "    for seq_index, seq_row in fTable.iterrows():\n",
    "        for prim_index, prim_row in primer.iterrows():\n",
    "            primerID = primer.iloc[prim_index,1]\n",
    "            #print seq_index + ' ' + primerID[start_index+0:start_index+15]\n",
    "            if seq_index == primerID[start_index:start_index+15]:\n",
    "                fTable.at[seq_index,'ID'] = primer.iloc[prim_index,0]\n",
    "                primer.iloc[prim_index,2] = fTable.at[seq_index,'Frequency']\n",
    "    ##pd.set_option('display.max_rows', 208) ##allows you to view entirety of fTable w/o truncation\n",
    "\n",
    "    ##print (fTable)\n",
    "    \n",
    "    primer = primer.sort_values('Frequency',ascending=False)\n",
    "    primer = primer.reset_index()\n",
    "    del primer['index']\n",
    "    \n",
    "    ############################################################################\n",
    "    ##  Export primer frequency data as csv, managing file path\n",
    "    \n",
    "    csv_file = join (output_folder, os.path.splitext(os.path.basename(SeqFile))[0] + '_primerMatch.csv')\n",
    "    \n",
    "    ##csv_file = join(output_folder, os.path.splitext(SeqFile)[0] + '_primerMatch.csv')\n",
    "\n",
    "    primer.to_csv(csv_file, sep='\\t', index=False)\n",
    "    primercsv = pd.read_csv('primerMatch.csv',sep='\\t')\n",
    "    #print(primercsv)\n",
    "\n",
    "\n",
    "for f in listdir(SeqFilePath):\n",
    "    if not f.startswith('.'):\n",
    "        ## In R2 file, sequencing left off first base, readjusted index to shift one right\n",
    "        if '_R2_' in f:\n",
    "            ##primerfreq(f,1)\n",
    "            primerfreq(join(SeqFilePath,f),1)\n",
    "        if '_R1_' in f:\n",
    "            ##primerfreq(f,0)\n",
    "\n",
    "            primerfreq(join(SeqFilePath, f),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-1_S2_L001_001.fastq\n",
      "1-1_S2_L001_001.fastq\n",
      "36_S31_L001_001.fastq\n",
      "36_S31_L001_001.fastq\n"
     ]
    }
   ],
   "source": [
    "## Code for creating doc of paired primers \n",
    "\n",
    "sep_reads = '/Users/annechen/Downloads/CRISPR Pools Data/test'\n",
    "\n",
    "############################################################################\n",
    "## Finding matching files in the folder to designate R1 as forward and R2 as reverse\n",
    "\n",
    "fastq_data = []\n",
    "\n",
    "for f1 in listdir(sep_reads):\n",
    "    if '_R1_' in f1 and not f1.startswith('.'):\n",
    "        forward_f = f1\n",
    "        for f2 in listdir(sep_reads):\n",
    "            if '_R2_' in f2 and not f2.startswith('.'):\n",
    "                if f1.replace('_R1','') == f2.replace('_R2',''):\n",
    "                    reverse_f = f2\n",
    "                    \n",
    "                    ############################################################################\n",
    "                    ## Creating dataframe with ID, forward, and reverse reads\n",
    "                    \n",
    "                    with open (join(sep_reads,f1), 'rU') as forward:\n",
    "                        for forward_data in SeqIO.parse(forward, 'fastq'):\n",
    "                            fastq_data.append([str(forward_data.id), str(forward_data.seq)])\n",
    "                    \n",
    "                    fastq_df = pd.DataFrame(fastq_data, columns = ['read_ID', 'forward'])\n",
    "                    index_pos = 0\n",
    "                    \n",
    "                    fastq_df['reverse'] = ''\n",
    "                    with open (join(sep_reads,f2),'rU') as reverse:\n",
    "                        for reverse_data in SeqIO.parse(reverse, 'fastq'):\n",
    "                            rev_code = str(reverse_data.seq)\n",
    "                            ##print fastq_df.at[index_pos, 'read_ID']\n",
    "                            if str(reverse_data.id) == fastq_df.at[index_pos,'read_ID']:\n",
    "                                fastq_df.at[index_pos, 'reverse'] = rev_code\n",
    "                                index_pos += 1\n",
    "                                \n",
    "                    ############################################################################            \n",
    "                    ## Making file name            \n",
    "                    initial_file_name = os.path.basename(f1.replace('_R1',''))\n",
    "                    combined_file = join(sep_reads, os.path.splitext(initial_file_name)[0] + '_combined.csv')\n",
    "                    \n",
    "                    ##print (initial_file_name)\n",
    "                    ##print os.path.basename(initial_file_name)\n",
    "                    ##os.path.splitext(os.path.basename(SeqFile))[0] \n",
    "                    ## Making csv file\n",
    "                    fastq_df.to_csv(combined_file, sep='\\t', index=False)\n",
    "                    ##fastqcsv = pd.read_csv()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils import MeltingTemp as mt\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import generic_dna, generic_protein\n",
    "import sys\n",
    "import os\n",
    "from Bio.SeqIO.QualityIO import FastqGeneralIterator\n",
    "from Bio.Blast import NCBIXML\n",
    "from Bio.Blast.Applications import NcbiblastxCommandline\n",
    "from Bio.Seq import Seq\n",
    "import subprocess\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "sep_reads = '/Users/annechen/Downloads/CRISPR Pools Data/test'\n",
    "PrimerID = '/Users/annechen/Downloads/sgRNAs for multiplexed CRISPR - Primer Sequences Only.csv'\n",
    "\n",
    "############################################################################\n",
    "## Creating output folder to put results in\n",
    "\n",
    "output_folder = join(sep_reads, 'results')\n",
    "## Put data in separate output_folder\n",
    "if not os.path.isdir(output_folder): \n",
    "    os.mkdir(output_folder)\n",
    "    \n",
    "############################################################################\n",
    "## Create function to analyze combined reads csv file and split data into the 6 docs\n",
    "                    \n",
    "def pairAnalyze(CombSeqFile, PrimerIDFile):\n",
    "    \n",
    "    comb_reads = pd.read_csv(CombSeqFile, sep='\\t')\n",
    "    primer = pd.read_csv(PrimerIDFile)\n",
    "    \n",
    "    ############################################################################\n",
    "    ## Create 6 dataframes to hold different information\n",
    "\n",
    "    concordant = pd.DataFrame(columns = ['read_ID', 'forward', 'reverse'])\n",
    "    discordant = pd.DataFrame(columns = ['read_ID', 'forward', 'reverse'])\n",
    "    onematch = pd.DataFrame(columns = ['read_ID', 'forward', 'reverse'])\n",
    "    nomatch = pd.DataFrame(columns = ['read_ID', 'forward', 'reverse'])\n",
    "    freqTable = pd.DataFrame(columns = ['Forward Prim ID', 'Reverse Prim ID', 'Frequency'])\n",
    "    aggData = {}\n",
    "    \n",
    "    ############################################################################\n",
    "    ## Load PrimerID values into freqTable\n",
    "\n",
    "    ## Need to change this part of code according to name of primer sequences\n",
    "    for index, row in primer.iterrows():\n",
    "        if index == 30:\n",
    "            break\n",
    "        freqTable = freqTable.append({'Forward Prim ID':primer.iloc[index,0],'Reverse Prim ID':primer.iloc[index+30, 0], 'Frequency':0}, ignore_index=True)\n",
    "\n",
    "    ############################################################################\n",
    "    ## Iterate through combined list to sort read pairs\n",
    "\n",
    "    for seq_index, seq_row in comb_reads.iterrows():\n",
    "\n",
    "        fseq = comb_reads.iloc[seq_index,1]\n",
    "        rseq = comb_reads.iloc[seq_index,2]\n",
    "\n",
    "        ##Gfor and Grev = True if there is G-Tail at end of sequence, False if there is no G-tail\n",
    "        Gfor = fseq[-8:] == 'GGGGGGGG'\n",
    "        Grev = rseq[-8:] == 'GGGGGGGG'\n",
    "        ##fID and rID will be changed later if a match is found and there is no G-tail\n",
    "        fID = 'no forward match'\n",
    "        rID = 'no reverse match'\n",
    "        \n",
    "        ############################################################################\n",
    "        ## Match each read without a G-tail to a read ID\n",
    "\n",
    "        if not Gfor or not Grev:\n",
    "            for p_index, p_row in primer.iterrows():\n",
    "                primerID = primer.iloc[p_index,1]\n",
    "\n",
    "                if not Gfor and fseq[0:15] == primerID[0:15]:\n",
    "                    fID = primer.iloc[p_index, 0]\n",
    "                if not Grev and rseq[0:15] == primerID[1:16]:\n",
    "                    rIDcode = primer.iloc[p_index, 0]\n",
    "                    ## Need to change this part of code according to name of primer sequences (manually matches rev code to forward by subtracting 30)\n",
    "                    rID = rIDcode[0:2] + str(int(rIDcode[2:])-30)\n",
    "\n",
    "        ############################################################################\n",
    "        ## Sort read into one of four categories depending on presence of G-Tail and PrimerID Match\n",
    "\n",
    "        if Gfor and Grev:\n",
    "            nomatch = pd.concat([nomatch, comb_reads.iloc[[seq_index]]])\n",
    "\n",
    "        elif fID == rID:\n",
    "            ## print 'concordant ' + comb_reads.iloc[seq_index, 0][-4:]\n",
    "            concordant = pd.concat([concordant, comb_reads.iloc[[seq_index]]])\n",
    "\n",
    "            ## Input info into concordant pair frequency table\n",
    "            for index, row in freqTable.iterrows():\n",
    "                if fID == freqTable.iloc[index,0]:\n",
    "                    freqTable.iloc[index,2] += 1\n",
    "                \n",
    "        elif fID != 'no forward match' and rID != 'no reverse match':\n",
    "            ## print 'discordant ' + comb_reads.iloc[seq_index, 0][-4:]\n",
    "            discordant = pd.concat([discordant, comb_reads.iloc[[seq_index]]])\n",
    "\n",
    "        elif fID != 'no forward match' or rID != 'no reverse match':\n",
    "            onematch = pd.concat([onematch, comb_reads.iloc[[seq_index]]])\n",
    "            ## print 'one match ' + comb_reads.iloc[seq_index, 0][-4:]\n",
    "\n",
    "        else:\n",
    "            nomatch = pd.concat([nomatch, comb_reads.iloc[[seq_index]]])\n",
    "\n",
    "    ## Sort freqTable for primer freq from largest to smallest\n",
    "    freqTable = freqTable.sort_values('Frequency', ascending=False)\n",
    "    freqTable = freqTable.reset_index()\n",
    "    del freqTable['index']\n",
    "\n",
    "    ############################################################################\n",
    "    ## Creating aggregate data dictionary and load into new dataframe\n",
    "\n",
    "    aggData['Concordant'] = len(concordant.index)\n",
    "    aggData['Discordant'] = len(discordant.index)\n",
    "    aggData['One ID Match'] = len(onematch.index)\n",
    "    aggData['No ID Match'] = len(nomatch.index)\n",
    "\n",
    "    aggData_df = pd.DataFrame(aggData.items(), columns=['Pair Type', 'Frequency'])\n",
    "\n",
    "    ############################################################################\n",
    "    ## Create csv files for each dataframe\n",
    "\n",
    "    concord_csv = join(os.path.dirname(CombSeqFile), os.path.splitext(os.path.basename(CombSeqFile))[0] + '_concordant_file.csv')\n",
    "    concordant.to_csv(concord_csv, sep='\\t', index=False)\n",
    "\n",
    "    discord_csv = join(os.path.dirname(CombSeqFile), os.path.splitext(os.path.basename(CombSeqFile))[0] + '_discordant_file.csv')\n",
    "    discordant.to_csv(discord_csv, sep='\\t', index=False)\n",
    "\n",
    "    onematch_csv = join(os.path.dirname(CombSeqFile), os.path.splitext(os.path.basename(CombSeqFile))[0] + '_single_match_file.csv')\n",
    "    onematch.to_csv(onematch_csv, sep='\\t', index=False)\n",
    "\n",
    "    nomatch_csv = join(os.path.dirname(CombSeqFile), os.path.splitext(os.path.basename(CombSeqFile))[0] + '_no_matches_file.csv')\n",
    "    nomatch.to_csv(nomatch_csv, sep='\\t', index=False)\n",
    "\n",
    "    freqTable_csv = join(os.path.dirname(CombSeqFile), os.path.splitext(os.path.basename(CombSeqFile))[0] + '_concordant_freqTable.csv')\n",
    "    freqTable.to_csv(freqTable_csv, sep='\\t', index=False)\n",
    "\n",
    "    aggData_df_csv = join(os.path.dirname(CombSeqFile), os.path.splitext(os.path.basename(CombSeqFile))[0] + '_aggregate_data.csv')\n",
    "    aggData_df.to_csv(aggData_df_csv, sep='\\t', index=False)\n",
    "\n",
    "############################################################################\n",
    "## Fill results folder with combined reads pooling paired separate reads together\n",
    "\n",
    "for f1 in listdir(sep_reads):\n",
    "    if '_R1_' in f1 and not f1.startswith('.'):\n",
    "        forward_f = f1\n",
    "        for f2 in listdir(sep_reads):\n",
    "            if '_R2_' in f2 and not f2.startswith('.'):\n",
    "                if f1.replace('_R1','') == f2.replace('_R2',''):\n",
    "                    \n",
    "                    fastq_data = []\n",
    "                    reverse_f = f2\n",
    "                    \n",
    "                    ############################################################################\n",
    "                    ## Creating dataframe with ID, forward, and reverse reads\n",
    "                    \n",
    "                    with open (join(sep_reads,f1), 'rU') as forward:\n",
    "                        for forward_data in SeqIO.parse(forward, 'fastq'):\n",
    "                            fastq_data.append([str(forward_data.id), str(forward_data.seq)])\n",
    "                    \n",
    "                    fastq_df = pd.DataFrame(fastq_data, columns = ['read_ID', 'forward'])\n",
    "                    index_pos = 0\n",
    "                    \n",
    "                    fastq_df['reverse'] = ''\n",
    "                    with open (join(sep_reads,f2),'rU') as reverse:\n",
    "                        for reverse_data in SeqIO.parse(reverse, 'fastq'):\n",
    "                            rev_code = str(reverse_data.seq)\n",
    "                            ##print fastq_df.at[index_pos, 'read_ID']\n",
    "                            if str(reverse_data.id) == fastq_df.at[index_pos,'read_ID']:\n",
    "                                fastq_df.at[index_pos, 'reverse'] = rev_code\n",
    "                                index_pos += 1\n",
    "                                \n",
    "                    ############################################################################            \n",
    "                    ## Making file name            \n",
    "                    initial_file_name = os.path.basename(f1.replace('_R1',''))\n",
    "                    combined_file = join(output_folder, os.path.splitext(initial_file_name)[0] + '_combined.csv')\n",
    "                    \n",
    "                    ## Making csv file\n",
    "                    fastq_df.to_csv(combined_file, sep='\\t', index=False)\n",
    "\n",
    "## Load CSV File of Primer IDs into pandas dataframe\n",
    "##primer = pd.read_csv(PrimerID)\n",
    "\n",
    "for f in listdir(output_folder):\n",
    "    if not f.startswith('.'):\n",
    "        pairAnalyze(join(output_folder, f), PrimerID)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrimerID = '/Users/annechen/Downloads/sgRNAs for multiplexed CRISPR - Primer Sequences Only.csv'\n",
    "combined = '/Users/annechen/Downloads/CRISPR Pools Data/test2/results/1-1_S2_L001_001_combined.csv'\n",
    "path = '/Users/annechen/Downloads/CRISPR Pools Data/test2/results'\n",
    "\n",
    "\n",
    "comb_reads = pd.read_csv(combined, sep='\\t')\n",
    "primer = pd.read_csv(PrimerID)\n",
    "primer.head()\n",
    "\n",
    "############################################################################\n",
    "## Create 6 dataframes to hold different information\n",
    "\n",
    "concordant = pd.DataFrame(columns = ['read_ID', 'forward', 'reverse'])\n",
    "discordant = pd.DataFrame(columns = ['read_ID', 'forward', 'reverse'])\n",
    "onematch = pd.DataFrame(columns = ['read_ID', 'forward', 'reverse'])\n",
    "nomatch = pd.DataFrame(columns = ['read_ID', 'forward', 'reverse'])\n",
    "freqTable = pd.DataFrame(columns = ['Forward Prim ID', 'Reverse Prim ID', 'Frequency'])\n",
    "aggData = {}\n",
    "\n",
    "############################################################################\n",
    "## Load PrimerID values into freqTable\n",
    "\n",
    "## Need to change this part of code according to name of primer sequences\n",
    "for index, row in primer.iterrows():\n",
    "    if index == 30:\n",
    "        break\n",
    "    freqTable = freqTable.append({'Forward Prim ID':primer.iloc[index,0],'Reverse Prim ID':primer.iloc[index+30, 0], 'Frequency':0}, ignore_index=True)\n",
    "                         \n",
    "############################################################################\n",
    "## Iterate through combined list to sort read pairs\n",
    "\n",
    "for seq_index, seq_row in comb_reads.iterrows():\n",
    "    \n",
    "    fseq = comb_reads.iloc[seq_index,1]\n",
    "    rseq = comb_reads.iloc[seq_index,2]\n",
    "    \n",
    "    ##Gfor and Grev = True if there is G-Tail at end of sequence, False if there is no G-tail\n",
    "    Gfor = fseq[-8:] == 'GGGGGGGG'\n",
    "    Grev = rseq[-8:] == 'GGGGGGGG'\n",
    "    ##fID and rID will be changed later if a match is found and there is no G-tail\n",
    "    fID = 'no forward match'\n",
    "    rID = 'no reverse match'\n",
    "    \n",
    "    ############################################################################\n",
    "    ## Match each read without a G-tail to a read ID\n",
    "    \n",
    "    if not Gfor or not Grev:\n",
    "        for p_index, p_row in primer.iterrows():\n",
    "            primerID = primer.iloc[p_index,1]\n",
    "\n",
    "            if not Gfor and fseq[0:15] == primerID[0:15]:\n",
    "                fID = primer.iloc[p_index, 0]\n",
    "            if not Grev and rseq[0:15] == primerID[1:16]:\n",
    "                rIDcode = primer.iloc[p_index, 0]\n",
    "                ## Need to change this part of code according to name of primer sequences (manually matches rev code to forward by subtracting 30)\n",
    "                rID = rIDcode[0:2] + str(int(rIDcode[2:])-30)\n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    ## Sort read into one of four categories depending on presence of G-Tail and PrimerID Match\n",
    "    \n",
    "    if Gfor and Grev:\n",
    "        nomatch = pd.concat([nomatch, comb_reads.iloc[[seq_index]]])\n",
    "        \n",
    "    elif fID == rID:\n",
    "        ## print 'concordant ' + comb_reads.iloc[seq_index, 0][-4:]\n",
    "        concordant = pd.concat([concordant, comb_reads.iloc[[seq_index]]])\n",
    "        \n",
    "        ## Input info into concordant pair frequency table\n",
    "        for index, row in freqTable.iterrows():\n",
    "            if fID == freqTable.iloc[index,0]:\n",
    "                freqTable.iloc[index,2] += 1\n",
    "        \n",
    "    elif fID != 'no forward match' and rID != 'no reverse match':\n",
    "        ## print 'discordant ' + comb_reads.iloc[seq_index, 0][-4:]\n",
    "        discordant = pd.concat([discordant, comb_reads.iloc[[seq_index]]])\n",
    "        \n",
    "    elif fID != 'no forward match' or rID != 'no reverse match':\n",
    "        onematch = pd.concat([onematch, comb_reads.iloc[[seq_index]]])\n",
    "        ## print 'one match ' + comb_reads.iloc[seq_index, 0][-4:]\n",
    "        \n",
    "    else:\n",
    "        nomatch = pd.concat([nomatch, comb_reads.iloc[[seq_index]]])\n",
    "\n",
    "## Sort freqTable for primer freq from largest to smallest\n",
    "freqTable = freqTable.sort_values('Frequency', ascending=False)\n",
    "freqTable = freqTable.reset_index()\n",
    "del freqTable['index']\n",
    "\n",
    "############################################################################\n",
    "## Creating aggregate data dictionary and load into new dataframe\n",
    "\n",
    "aggData['Concordant'] = len(concordant.index)\n",
    "aggData['Discordant'] = len(discordant.index)\n",
    "aggData['One ID Match'] = len(onematch.index)\n",
    "aggData['No ID Match'] = len(nomatch.index)\n",
    "\n",
    "aggData_df = pd.DataFrame(aggData.items(), columns=['Pair Type', 'Frequency'])\n",
    "\n",
    "############################################################################\n",
    "## Create csv files for each dataframe\n",
    "\n",
    "concord_csv = join(path, os.path.splitext(os.path.basename(combined))[0] + '_concordant_file.csv')\n",
    "concordant.to_csv(concord_csv, sep='\\t', index=False)\n",
    "\n",
    "discord_csv = join(path, os.path.splitext(os.path.basename(combined))[0] + '_discordant_file.csv')\n",
    "discordant.to_csv(discord_csv, sep='\\t', index=False)\n",
    "\n",
    "onematch_csv = join(path, os.path.splitext(os.path.basename(combined))[0] + '_single_match_file.csv')\n",
    "onematch.to_csv(onematch_csv, sep='\\t', index=False)\n",
    "\n",
    "nomatch_csv = join(path, os.path.splitext(os.path.basename(combined))[0] + '_no_matches_file.csv')\n",
    "nomatch.to_csv(nomatch_csv, sep='\\t', index=False)\n",
    "\n",
    "freqTable_csv = join(path, os.path.splitext(os.path.basename(combined))[0] + '_concordant_freqTable.csv')\n",
    "freqTable.to_csv(freqTable_csv, sep='\\t', index=False)\n",
    "\n",
    "aggData_df_csv = join(path, os.path.splitext(os.path.basename(combined))[0] + '_aggregate_data.csv')\n",
    "aggData_df.to_csv(aggData_df_csv, sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Corrected Primer Name                    Sequence\n",
      "0                 JH441       CTGGGACCCGACAGTTGTCAT\n",
      "1                 JH442     CACACGCACATTCGACAAATGGA\n",
      "2                 JH443  CCCATAGAAGCCTCCTGCTTTAATCT\n",
      "3                 JH444        AATCGCCATGGAAAACGCGG\n",
      "4                 JH445    TGGCTTGAAAACGAGTTGAAAGCG\n",
      "JH442\n",
      "JH412\n"
     ]
    }
   ],
   "source": [
    "PrimerID = '/Users/annechen/Downloads/sgRNAs for multiplexed CRISPR - Primer Sequences Only.csv'\n",
    "combined = '/Users/annechen/Downloads/CRISPR Pools Data/test2/results/1-1_S2_L001_001_combined.csv'\n",
    "\n",
    "comb_reads = pd.read_csv(combined, sep='\\t')\n",
    "primer = pd.read_csv(PrimerID)\n",
    "\n",
    "print(primer.head())\n",
    "old_id = primer.iloc[1,0]\n",
    "new_id = old_id[0:2] + str(int(old_id[2:])-30)\n",
    "print old_id\n",
    "print new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statement 1 passed\n",
      "bleh\n"
     ]
    }
   ],
   "source": [
    "##discordant = pd.concat([comb_reads.iloc[[0]],discordant])\n",
    "##discordant = pd.concat([comb_reads.iloc[[1]],discordant])\n",
    "##discordant = pd.concat([discordant, comb_reads.iloc[[4]]])\n",
    "\n",
    "##discordant.concat(comb_reads.iloc[[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair Type</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concordant</td>\n",
       "      <td>53779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>discordant</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pair Type  Frequency\n",
       "0  concordant      53779\n",
       "1  discordant         60"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PrimerID = '/Users/annechen/Downloads/sgRNAs for multiplexed CRISPR - Primer Sequences Only.csv'\n",
    "combined = '/Users/annechen/Downloads/CRISPR Pools Data/test2/results/1-1_S2_L001_001_combined.csv'\n",
    "\n",
    "comb_reads = pd.read_csv(combined, sep='\\t')\n",
    "primer = pd.read_csv(PrimerID)\n",
    "primer.head()\n",
    "\n",
    "############################################################################\n",
    "## Create 6 dataframes to hold different information\n",
    "\n",
    "concordant = pd.DataFrame(columns = ['read_ID', 'forward', 'reverse'])\n",
    "discordant = pd.DataFrame(columns = ['read_ID', 'forward', 'reverse'])\n",
    "onematch = pd.DataFrame(columns = ['read_ID', 'forward', 'reverse'])\n",
    "nomatch = pd.DataFrame(columns = ['read_ID', 'forward', 'reverse'])\n",
    "freqTable = pd.DataFrame(columns = ['Forward Prim ID', 'Reverse Prim ID'])\n",
    "\n",
    "\n",
    "aggData = {}\n",
    "aggData['concordant'] = len(comb_reads.index)\n",
    "aggData['discordant'] = len(primer.index)\n",
    "\n",
    "aggData_df = pd.DataFrame(aggData.items(), columns=['Pair Type', 'Frequency'])\n",
    "aggData_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/annechen/Downloads/CRISPR Pools Data/test/results is the output folder\n",
      "\n",
      "1-1_S2_L001_R1_001.fastq is the file in it\n",
      "1-1_S2_L001_R2_001.fastq is the file in it\n",
      "36_S31_L001_R1_001.fastq is the file in it\n",
      "36_S31_L001_R2_001.fastq is the file in it\n",
      "results is the file in it\n"
     ]
    }
   ],
   "source": [
    "sep_reads = '/Users/annechen/Downloads/CRISPR Pools Data/test'\n",
    "PrimerID = '/Users/annechen/Downloads/sgRNAs for multiplexed CRISPR - Primer Sequences Only.csv'\n",
    "\n",
    "############################################################################\n",
    "## Creating output folder to put results in\n",
    "\n",
    "output_folder = join(sep_reads, 'results')\n",
    "## Put data in separate output_folder\n",
    "if not os.path.isdir(output_folder): \n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "print output_folder + ' is the output folder\\n'\n",
    "for f in listdir(sep_reads):\n",
    "    if not f.startswith('.'):\n",
    "        print f + ' is the file in it'\n",
    "        ##pairAnalyze(join(output_folder, f), PrimerID)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
